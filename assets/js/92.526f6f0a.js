(window.webpackJsonp=window.webpackJsonp||[]).push([[92],{449:function(s,t,n){"use strict";n.r(t);var a=n(44),e=Object(a.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("h1",{attrs:{id:"_3-深度学习基础"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-深度学习基础"}},[s._v("#")]),s._v(" 3.深度学习基础")]),s._v(" "),n("h2",{attrs:{id:"_3-2线性回归的从零开始实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-2线性回归的从零开始实现"}},[s._v("#")]),s._v(" 3.2线性回归的从零开始实现")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" IPython "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" display\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" matplotlib "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" random\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.2.1生成数据集")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输入个数（特征数）：2")]),s._v("\nnum_inputs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练数据集样本数：1000")]),s._v("\nnum_examples "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 线性回归模型真实权重w=[2,-3.4]T")]),s._v("\ntrue_w "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 偏差b：4.2")]),s._v("\ntrue_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.2")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 生成批量样本特征X")]),s._v("\nfeatures "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("randn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("float32"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 生成标签y=X*w+b+ϵ")]),s._v("\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" true_b\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 噪声项ϵ服从均值为0、标准差为0.01的正态分布")]),s._v("\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" size"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("float32"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# features的每一行是一个长度为2的向量，而labels的每一行是一个长度为1的向量（标量）")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tensor([ 0.4093, -0.3614]) tensor(6.2407)")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("use_svg_display")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 用矢量图显示")]),s._v("\n    display"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("display_svg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'svg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("set_figsize")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("figsize"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    use_svg_display"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置图的尺寸")]),s._v("\n    plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'figure.figsize'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" figsize\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# # 在../d2lzh_pytorch里面添加上面两个函数后就可以这样导入")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# import sys")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v('# sys.path.append("..")')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# from d2lzh_pytorch import *")]),s._v("\n\nset_figsize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("numpy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("numpy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.2.2读取数据")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("data_iter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    num_examples "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    indices "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shuffle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("indices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        j "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("LongTensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("indices"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("min")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("index_select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("index_select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\nbatch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Y "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" data_iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("break")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tensor([[ 0.6490,  1.0697],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 0.5235, -0.1836],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 0.9550, -0.6315],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-0.6130, -1.9139],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 2.7174, -0.2753],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-0.2227, -0.7703],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-3.2678, -0.0340],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 1.7480,  0.2610],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-0.9680, -0.5556],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-0.1723,  1.0400]]) tensor([ 1.8639,  5.8756,  8.2686,  9.4674, 10.5612,  6.3901, -2.2234,  6.8192,")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#          4.1531,  0.3223])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.2.3初始化模型参数")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将权重初始化成均值为0、标准差为0.01的正态随机数，偏差则初始化成0")]),s._v("\nw "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("float32"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nb "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zeros"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("float32"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 之后的模型训练中，需要对这些参数求梯度来迭代参数的值，因此我们要让它们的requires_grad=True")]),s._v("\nw"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("requires_grad_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("requires_grad"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("requires_grad_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("requires_grad"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.2.4定义模型")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用mm函数做矩阵乘法")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("linreg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.2.5定义损失函数")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("squared_loss")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_hat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 注意这里返回的是向量, 另外, pytorch里的MSELoss并没有除以2")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_hat "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_hat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.2.6定义优化算法")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("sgd")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" param "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        param"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-=")]),s._v(" lr "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" param"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" batch_size\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.2.7训练模型")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 迭代周期个数num_epochs和学习率lr")]),s._v("\nlr "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.03")]),s._v("\nnum_epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" linreg\nloss "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" squared_loss\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" epoch "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_epochs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练模型一共需要num_epochs个迭代周期")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在每一个迭代周期中，会使用训练数据集中所有样本一次（假设样本数能够被批量大小整除）")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# X和y分别是小批量样本的特征和标签")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" data_iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        l "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# l是有关小批量X和y的损失")]),s._v("\n        l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 小批量的损失对模型参数求梯度")]),s._v("\n        sgd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用小批量随机梯度下降迭代模型参数")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 不要忘了梯度清零")]),s._v("\n        w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    train_l "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'epoch %d, loss %f'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("epoch "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" train_l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# epoch 1,loss 0.030597")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# epoch 2,loss 0.000101")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# epoch 3,loss 0.000048")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\n'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [2, -3.4]")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#  tensor([[ 2.0002],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-3.4003]], requires_grad=True)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("true_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\n'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 4.2")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#  tensor([4.1993], requires_grad=True)")]),s._v("\n\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br"),n("span",{staticClass:"line-number"},[s._v("75")]),n("br"),n("span",{staticClass:"line-number"},[s._v("76")]),n("br"),n("span",{staticClass:"line-number"},[s._v("77")]),n("br"),n("span",{staticClass:"line-number"},[s._v("78")]),n("br"),n("span",{staticClass:"line-number"},[s._v("79")]),n("br"),n("span",{staticClass:"line-number"},[s._v("80")]),n("br"),n("span",{staticClass:"line-number"},[s._v("81")]),n("br"),n("span",{staticClass:"line-number"},[s._v("82")]),n("br"),n("span",{staticClass:"line-number"},[s._v("83")]),n("br"),n("span",{staticClass:"line-number"},[s._v("84")]),n("br"),n("span",{staticClass:"line-number"},[s._v("85")]),n("br"),n("span",{staticClass:"line-number"},[s._v("86")]),n("br"),n("span",{staticClass:"line-number"},[s._v("87")]),n("br"),n("span",{staticClass:"line-number"},[s._v("88")]),n("br"),n("span",{staticClass:"line-number"},[s._v("89")]),n("br"),n("span",{staticClass:"line-number"},[s._v("90")]),n("br"),n("span",{staticClass:"line-number"},[s._v("91")]),n("br"),n("span",{staticClass:"line-number"},[s._v("92")]),n("br"),n("span",{staticClass:"line-number"},[s._v("93")]),n("br"),n("span",{staticClass:"line-number"},[s._v("94")]),n("br"),n("span",{staticClass:"line-number"},[s._v("95")]),n("br"),n("span",{staticClass:"line-number"},[s._v("96")]),n("br"),n("span",{staticClass:"line-number"},[s._v("97")]),n("br"),n("span",{staticClass:"line-number"},[s._v("98")]),n("br"),n("span",{staticClass:"line-number"},[s._v("99")]),n("br"),n("span",{staticClass:"line-number"},[s._v("100")]),n("br"),n("span",{staticClass:"line-number"},[s._v("101")]),n("br"),n("span",{staticClass:"line-number"},[s._v("102")]),n("br"),n("span",{staticClass:"line-number"},[s._v("103")]),n("br"),n("span",{staticClass:"line-number"},[s._v("104")]),n("br"),n("span",{staticClass:"line-number"},[s._v("105")]),n("br"),n("span",{staticClass:"line-number"},[s._v("106")]),n("br"),n("span",{staticClass:"line-number"},[s._v("107")]),n("br"),n("span",{staticClass:"line-number"},[s._v("108")]),n("br"),n("span",{staticClass:"line-number"},[s._v("109")]),n("br"),n("span",{staticClass:"line-number"},[s._v("110")]),n("br"),n("span",{staticClass:"line-number"},[s._v("111")]),n("br"),n("span",{staticClass:"line-number"},[s._v("112")]),n("br"),n("span",{staticClass:"line-number"},[s._v("113")]),n("br"),n("span",{staticClass:"line-number"},[s._v("114")]),n("br"),n("span",{staticClass:"line-number"},[s._v("115")]),n("br"),n("span",{staticClass:"line-number"},[s._v("116")]),n("br"),n("span",{staticClass:"line-number"},[s._v("117")]),n("br"),n("span",{staticClass:"line-number"},[s._v("118")]),n("br"),n("span",{staticClass:"line-number"},[s._v("119")]),n("br"),n("span",{staticClass:"line-number"},[s._v("120")]),n("br"),n("span",{staticClass:"line-number"},[s._v("121")]),n("br"),n("span",{staticClass:"line-number"},[s._v("122")]),n("br"),n("span",{staticClass:"line-number"},[s._v("123")]),n("br"),n("span",{staticClass:"line-number"},[s._v("124")]),n("br"),n("span",{staticClass:"line-number"},[s._v("125")]),n("br"),n("span",{staticClass:"line-number"},[s._v("126")]),n("br"),n("span",{staticClass:"line-number"},[s._v("127")]),n("br"),n("span",{staticClass:"line-number"},[s._v("128")]),n("br"),n("span",{staticClass:"line-number"},[s._v("129")]),n("br"),n("span",{staticClass:"line-number"},[s._v("130")]),n("br"),n("span",{staticClass:"line-number"},[s._v("131")]),n("br"),n("span",{staticClass:"line-number"},[s._v("132")]),n("br")])]),n("p",[n("strong",[s._v("小结")])]),s._v(" "),n("ul",[n("li",[s._v("仅使用"),n("code",[s._v("Tensor")]),s._v("和"),n("code",[s._v("autograd")]),s._v("模块就可以很容易地实现一个模型。")])]),s._v(" "),n("h2",{attrs:{id:"_3-3线性回归的简洁实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-3线性回归的简洁实现"}},[s._v("#")]),s._v(" 3.3线性回归的简洁实现")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" Data\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" torch "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" nn\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.3.1 生成数据集")]),s._v("\nnum_inputs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\nnum_examples "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v("\ntrue_w "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\ntrue_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.2")]),s._v("\nfeatures "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_examples"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" true_b\nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" size"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.3.2 读取数据")]),s._v("\nbatch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# PyTorch提供了data包来读取数据")]),s._v("\ndataset "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("TensorDataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndata_iter "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataLoader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" shuffle"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 让我们读取并打印第一个小批量数据样本")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" data_iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("break")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tensor([[ 1.2063,  0.4664],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-0.6526, -0.2680],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 2.7098,  0.9309],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-0.4368,  0.4329],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 0.3800,  0.5169],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 0.6877,  0.7135],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 0.2294, -1.8892],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 0.1931,  1.1560],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [-0.4655,  0.7612],")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         [ 1.4869,  1.0338]]) tensor([ 5.0169,  3.7947,  6.4541,  1.8473,  3.1957,  3.1510, 11.0968,  0.6451,")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#          0.6795,  3.6641])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.3.3 定义模型")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LinearNet")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" n_feature"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("LinearNet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__init__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linear "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n_feature"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# forward 定义前向传播")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        y "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" y\n\n\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" LinearNet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用print可以打印出网络的结构")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# LinearNet(")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#   (linear): Linear(in_features=2, out_features=1, bias=True)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# )")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 写法一")]),s._v("\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 此处还可以传入其他层")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# # 写法二")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# net = nn.Sequential()")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# net.add_module('linear', nn.Linear(num_inputs, 1))")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# # net.add_module ......")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# # 写法三")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# from collections import OrderedDict")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# net = nn.Sequential(OrderedDict([")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     ('linear', nn.Linear(num_inputs, 1))")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ]))")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Sequential(")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#   (0): Linear(in_features=2, out_features=1, bias=True)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# )")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Linear(in_features=2, out_features=1, bias=True)")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 通过net.parameters()来查看模型所有的可学习参数，此函数将返回一个生成器")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" param "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("param"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Parameter containing:")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tensor([[0.3085, 0.0713]], requires_grad=True)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Parameter containing:")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tensor([0.1828], requires_grad=True)")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.3.4 初始化模型参数")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nn "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" init\n\ninit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" mean"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" std"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ninit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("constant_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bias"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" val"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 也可以直接修改bias的data: net[0].bias.data.fill_(0)")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.3.5 定义损失函数")]),s._v("\nloss "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MSELoss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.3.6 定义优化算法")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optim "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" optim\n\noptimizer "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" optim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SGD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.03")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# SGD (")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Parameter Group 0")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     dampening: 0")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     lr: 0.03")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     momentum: 0")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     nesterov: False")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     weight_decay: 0")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# )")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 为不同子网络设置不同的学习率")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# optimizer = optim.SGD([")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     # 如果对某个参数不指定学习率，就使用最外层的默认学习率")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     {'params': net.subnet1.parameters()},  # 'lr': 0.03")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     {'params': net.subnet2.parameters(), 'lr': 0.01}")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ], lr=0.03)")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 调整学习率")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# for param_group in optimizer.param_groups:")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     param_group['lr'] *= 0.1  # 调整学习率为之前的0.1倍")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3.3.7 训练模型")]),s._v("\nnum_epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" epoch "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_epochs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" data_iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        output "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        l "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_grad"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        optimizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("step"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'epoch %d,loss:%f'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("epoch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" l"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# epoch 1,loss:7.306918")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# epoch 2,loss:7.323386")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# epoch 3,loss:1.303684")]),s._v("\n\ndense "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 从net获得需要的层，并访问其权重（weight）和偏差（bias）")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("true_w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [2, -3.4] Parameter containing:")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tensor([[ 2.0008, -3.3997]], requires_grad=True)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("true_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bias"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 4.2 Parameter containing:")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tensor([4.1996], requires_grad=True)")]),s._v("\n\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br"),n("span",{staticClass:"line-number"},[s._v("75")]),n("br"),n("span",{staticClass:"line-number"},[s._v("76")]),n("br"),n("span",{staticClass:"line-number"},[s._v("77")]),n("br"),n("span",{staticClass:"line-number"},[s._v("78")]),n("br"),n("span",{staticClass:"line-number"},[s._v("79")]),n("br"),n("span",{staticClass:"line-number"},[s._v("80")]),n("br"),n("span",{staticClass:"line-number"},[s._v("81")]),n("br"),n("span",{staticClass:"line-number"},[s._v("82")]),n("br"),n("span",{staticClass:"line-number"},[s._v("83")]),n("br"),n("span",{staticClass:"line-number"},[s._v("84")]),n("br"),n("span",{staticClass:"line-number"},[s._v("85")]),n("br"),n("span",{staticClass:"line-number"},[s._v("86")]),n("br"),n("span",{staticClass:"line-number"},[s._v("87")]),n("br"),n("span",{staticClass:"line-number"},[s._v("88")]),n("br"),n("span",{staticClass:"line-number"},[s._v("89")]),n("br"),n("span",{staticClass:"line-number"},[s._v("90")]),n("br"),n("span",{staticClass:"line-number"},[s._v("91")]),n("br"),n("span",{staticClass:"line-number"},[s._v("92")]),n("br"),n("span",{staticClass:"line-number"},[s._v("93")]),n("br"),n("span",{staticClass:"line-number"},[s._v("94")]),n("br"),n("span",{staticClass:"line-number"},[s._v("95")]),n("br"),n("span",{staticClass:"line-number"},[s._v("96")]),n("br"),n("span",{staticClass:"line-number"},[s._v("97")]),n("br"),n("span",{staticClass:"line-number"},[s._v("98")]),n("br"),n("span",{staticClass:"line-number"},[s._v("99")]),n("br"),n("span",{staticClass:"line-number"},[s._v("100")]),n("br"),n("span",{staticClass:"line-number"},[s._v("101")]),n("br"),n("span",{staticClass:"line-number"},[s._v("102")]),n("br"),n("span",{staticClass:"line-number"},[s._v("103")]),n("br"),n("span",{staticClass:"line-number"},[s._v("104")]),n("br"),n("span",{staticClass:"line-number"},[s._v("105")]),n("br"),n("span",{staticClass:"line-number"},[s._v("106")]),n("br"),n("span",{staticClass:"line-number"},[s._v("107")]),n("br"),n("span",{staticClass:"line-number"},[s._v("108")]),n("br"),n("span",{staticClass:"line-number"},[s._v("109")]),n("br"),n("span",{staticClass:"line-number"},[s._v("110")]),n("br"),n("span",{staticClass:"line-number"},[s._v("111")]),n("br"),n("span",{staticClass:"line-number"},[s._v("112")]),n("br"),n("span",{staticClass:"line-number"},[s._v("113")]),n("br"),n("span",{staticClass:"line-number"},[s._v("114")]),n("br"),n("span",{staticClass:"line-number"},[s._v("115")]),n("br"),n("span",{staticClass:"line-number"},[s._v("116")]),n("br"),n("span",{staticClass:"line-number"},[s._v("117")]),n("br"),n("span",{staticClass:"line-number"},[s._v("118")]),n("br"),n("span",{staticClass:"line-number"},[s._v("119")]),n("br"),n("span",{staticClass:"line-number"},[s._v("120")]),n("br"),n("span",{staticClass:"line-number"},[s._v("121")]),n("br"),n("span",{staticClass:"line-number"},[s._v("122")]),n("br"),n("span",{staticClass:"line-number"},[s._v("123")]),n("br"),n("span",{staticClass:"line-number"},[s._v("124")]),n("br"),n("span",{staticClass:"line-number"},[s._v("125")]),n("br"),n("span",{staticClass:"line-number"},[s._v("126")]),n("br"),n("span",{staticClass:"line-number"},[s._v("127")]),n("br"),n("span",{staticClass:"line-number"},[s._v("128")]),n("br"),n("span",{staticClass:"line-number"},[s._v("129")]),n("br"),n("span",{staticClass:"line-number"},[s._v("130")]),n("br"),n("span",{staticClass:"line-number"},[s._v("131")]),n("br"),n("span",{staticClass:"line-number"},[s._v("132")]),n("br"),n("span",{staticClass:"line-number"},[s._v("133")]),n("br"),n("span",{staticClass:"line-number"},[s._v("134")]),n("br"),n("span",{staticClass:"line-number"},[s._v("135")]),n("br"),n("span",{staticClass:"line-number"},[s._v("136")]),n("br"),n("span",{staticClass:"line-number"},[s._v("137")]),n("br"),n("span",{staticClass:"line-number"},[s._v("138")]),n("br"),n("span",{staticClass:"line-number"},[s._v("139")]),n("br"),n("span",{staticClass:"line-number"},[s._v("140")]),n("br"),n("span",{staticClass:"line-number"},[s._v("141")]),n("br"),n("span",{staticClass:"line-number"},[s._v("142")]),n("br")])]),n("p",[n("strong",[s._v("小结")])]),s._v(" "),n("ul",[n("li",[s._v("使用PyTorch可以更简洁地实现模型。")]),s._v(" "),n("li",[n("code",[s._v("torch.utils.data")]),s._v("模块提供了有关数据处理的工具")]),s._v(" "),n("li",[n("code",[s._v("torch.nn")]),s._v("模块定义了大量神经网络的层")]),s._v(" "),n("li",[n("code",[s._v("torch.nn.init")]),s._v("模块定义了各种初始化方法")]),s._v(" "),n("li",[n("code",[s._v("torch.optim")]),s._v("模块提供了很多常用的优化算法。")])])])}),[],!1,null,null,null);t.default=e.exports}}]);