(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{389:function(t,r,_){"use strict";_.r(r);var v=_(44),e=Object(v.a)({},(function(){var t=this,r=t.$createElement,_=t._self._c||r;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("h1",{attrs:{id:"机器学习-监督学习"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#机器学习-监督学习"}},[t._v("#")]),t._v(" 机器学习-监督学习")]),t._v(" "),_("p",[_("img",{attrs:{src:"https://pic4.zhimg.com/80/v2-7542f24bc4e5c200e80e728497f16813_720w.png",alt:"img"}})]),t._v(" "),_("p",[_("strong",[t._v("监督学习（Supervised learning）")]),t._v("：对于每个数据样本都进行标记")]),t._v(" "),_("p",[t._v("回归问题（regression problem）：（待补充）")]),t._v(" "),_("p",[t._v("分类问题（classification problem）：（待补充）")]),t._v(" "),_("p",[t._v("举例：")]),t._v(" "),_("p",[t._v("预测房价、医疗记录")]),t._v(" "),_("h3",{attrs:{id:"一、监督学习模型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#一、监督学习模型"}},[t._v("#")]),t._v(" 一、监督学习模型")]),t._v(" "),_("p",[t._v("共有三种模型：")]),t._v(" "),_("ul",[_("li",[t._v("非概率模型（Non-probabilistic Model）")]),t._v(" "),_("li",[t._v("概率判别模型（Probalilistic Discriminative Model）")]),t._v(" "),_("li",[t._v("生成模型（Generative Model）")])]),t._v(" "),_("p",[t._v("三种模型"),_("strong",[t._v("挖掘信息的程度从少到多")]),t._v("，"),_("strong",[t._v("解决问题的途径从直接到间接")])]),t._v(" "),_("p",[t._v("模型通常有两种分类方式：")]),t._v(" "),_("ul",[_("li",[_("p",[t._v("第一种是"),_("strong",[t._v("按模型形式分类：概率模型（Probabilistic Model）和 非概率模型（Non-probabilistic Model）")])])]),t._v(" "),_("li",[_("p",[t._v("第二种是"),_("strong",[t._v("按是否对观测变量的分布建模分类：判别模型（Discriminative Model）和 生成模型（Generative Model）")]),t._v("。")]),t._v(" "),_("p",[t._v("这两种分类方法事实上把所有模型划分成了三类，如下图所示：")])])]),t._v(" "),_("p",[_("img",{attrs:{src:"https://pic2.zhimg.com/80/v2-aa9107451a22ea33f5aa8cd323d1f015_720w.jpg",alt:"img"}})]),t._v(" "),_("center",[t._v("模型分类示意图")]),t._v(" "),_("p",[t._v("每种类别的代表性模型如下：")]),t._v(" "),_("p",[_("strong",[t._v("I. 非概率模型，直接判别")]),t._v("：感知机（单层神经网络，Perceptron）、多层感知机（MLP）、支持向量机（SVM）、K近邻（KNN）")]),t._v(" "),_("p",[_("strong",[t._v("II. 概率判别模型，间接利用条件概率判别")]),t._v("：逻辑回归（LR）、决策树（DT）、最大熵模型（ME）、条件随机场（CRF）")]),t._v(" "),_("p",[_("strong",[t._v("III. 生成模型，更间接地先求联合概率，然后利用贝叶斯定理判别")]),t._v("：高斯判别分析（GDA）、朴素贝叶斯（NB）、受限玻尔兹曼机（RBM）、隐马尔科夫模型（HMM）")]),t._v(" "),_("h3",{attrs:{id:"二、如何选择合适的监督学习算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二、如何选择合适的监督学习算法"}},[t._v("#")]),t._v(" 二、如何选择合适的监督学习算法")]),t._v(" "),_("p",[t._v("选择合适的监督学习算法取决于许多的因素，其中包括：")]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("数据值的形式")]),t._v("，连续还是离散；")]),t._v(" "),_("li",[_("strong",[t._v("数据的维度")]),t._v("，大还是小；")]),t._v(" "),_("li",[_("strong",[t._v("数据量")]),t._v("，多还是少；")]),t._v(" "),_("li",[t._v("可以利用的"),_("strong",[t._v("计算资源")]),t._v("，CPU或者GPU的计算能力；")]),t._v(" "),_("li",[t._v("对"),_("strong",[t._v("模型准确性和效率")]),t._v("的要求。")]),t._v(" "),_("li",[t._v("对"),_("strong",[t._v("模型可解释性")]),t._v("的要求。虽然学习如何权衡输入变量的复杂组合能够带来更准确的预测，但它也使得解释机器学习模型变得更困难。可被解释的预测模型生成的决策，是由原始输入变量带来的，而不是输入变量的任意高阶组合、缩放、加权组合带来的，所以对特征进行操作越直观的模型可解释性越强。")])]),t._v(" "),_("p",[t._v("通过对以上因素的分析，我们可以选择一个直观上比较合适的模型进行建模。")]),t._v(" "),_("p",[_("img",{attrs:{src:"https://pic3.zhimg.com/80/v2-ad2fd3174c4233db2648ff1a52a8be4a_720w.jpg",alt:"img"}}),t._v("图4 监督"),_("center",[t._v("监督学习模型选择表")])],1),t._v(" "),_("p",[t._v("此图来源于 "),_("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-cheat-sheet",target:"_blank",rel:"noopener noreferrer"}},[t._v("Microsoft Azure"),_("OutboundLink")],1),t._v("。首先毫无疑问，我们可以根据数据值的因变量，或者称之为"),_("strong",[t._v("标签，是连续值还是离散值，将监督学习问题分为分类问题和回归问题，其中分类问题的标签是离散值，回归问题的标签是连续值")]),t._v("。但是往后的节点，比如根据 准确率和效率、可解释性、数据量 等指标对算法进行取舍，我个人认为本图给的后续选择流程图过于宽泛了，只具备有限的参考价值。本文下面将从更细致的角度对各个算法进行分析。")]),t._v(" "),_("p",[_("img",{attrs:{src:"https://pic1.zhimg.com/80/v2-22942f2a524bce7151f41fc70165f780_720w.jpg",alt:"img"}})]),t._v(" "),_("p",[t._v("上述表格，对于训练和预测时间复杂度两列中，"),_("strong",[t._v("N 是训练样本数")]),t._v("，"),_("strong",[t._v("M 是样本特征维度")]),t._v("，其中支持向量机的")]),t._v(" "),_("p",[_("img",{attrs:{src:"https://pic2.zhimg.com/80/v2-8fbc7cc6e0e49a5e8d0b97908d6d8f79_720w.jpg",alt:"img"}})]),t._v(" "),_("p",[t._v("是支持向量的个数，神经网络的 "),_("strong",[t._v("P 是网络参数总个数")]),t._v("，K近邻表格中时间复杂度对应的方法是KD树法，决策树的 "),_("strong",[t._v("D 是决策树的层数")]),t._v("；另外需要注意，涉及到迭代法优化问题的模型，比如神经网络、逻辑回归等，它们的训练时间复杂度都是按照每个样本"),_("strong",[t._v("迭代常数次")]),t._v("计算的。")]),t._v(" "),_("p",[_("strong",[t._v("（以下部分待学习）")])]),t._v(" "),_("hr"),t._v(" "),_("p",[t._v("我们结合上述表格，一一分析各个模型的特点：")]),t._v(" "),_("ol",[_("li",[t._v("支持向量机，训练时间复杂度太高，这意味着样本数目太高训练效率很低；而且最后起作用的支持向量数目也是有限的，这意味着在特征维度一定的情况下，过多的训练样本数对模型预测准确率的提升也不大。所以综合两点，"),_("strong",[t._v("支持向量机适合小规模数据集")]),t._v("。")]),t._v(" "),_("li",[t._v("K近邻，没有显式的训练过程，它的特点是完全跟着数据走，没有数学模型可言，也正因为如此具有很强的可解释性。表格中给的是 KD 树实现的时间复杂度，如果是朴素方法，训练时间复杂度更低一点，是 O(N M)，但预测时间复杂度高达 O(N logK)，效率极低。即使使用 KD 树实现，当特征维度稍微大一点，效率也是极低；所以"),_("strong",[t._v("K近邻法特征维度一般不超过20，实用价值严重受限")]),t._v("。")]),t._v(" "),_("li",[t._v("神经网络，这里是以多层感知机（MLP）为例，现在深度学习层数和节点数目通常都比较大，所以网络参数个数P一般很大，P越大意味着越强的函数拟合能力，但前提是足够的计算资源和训练数据，所以说"),_("strong",[t._v("神经网络的表现效果一定程度上取决于计算资源和数据量")]),t._v("。")]),t._v(" "),_("li",[t._v("逻辑回归，训练和预测效率都很高，"),_("strong",[t._v("多维输出时的Softmax层通常作为现在深度学习的最后一层，使用广泛，效果也良好")]),t._v("。")]),t._v(" "),_("li",[t._v("决策树，决策树每个节点有十分具体的物理意义，所以有很强的解释性，训练效率较快，当我们希望能更好地理解手头数据的时候，往往可以使用决策树。但也是受限于其简单性，"),_("strong",[t._v("决策树更大的用处是作为一些更有用的算法的基石")]),t._v("，比如"),_("strong",[t._v("随机森林")]),t._v("，还有 BAT、华为等公司大数据比赛 几年前流行的算法 "),_("strong",[t._v("GBDT")]),t._v("，和最近几年流行的算法 "),_("strong",[t._v("XGBoost")]),t._v("。")]),t._v(" "),_("li",[t._v("朴素贝叶斯，跟K近邻类似，也没有显式的训练过程，因此也有较强的可解释性，这一点与图X结论不太一样哈。训练和预测效率效率都很高。"),_("strong",[t._v("典型的应用场景就是垃圾邮件过滤器，效果一般会很好")]),t._v("。")]),t._v(" "),_("li",[t._v("高斯判别模型，高斯判别模型是基于伯努利分布的，这一点与逻辑回归一致，事实上高斯判别模型求得的后验概率跟逻辑回归的函数形式也是一致的，差别就在于高斯判别模型多一个对各个类别数据本身的分布假设——高斯分布，这意味着高斯判别模型比逻辑回归需要更加严格的模型假设，在实践中，"),_("strong",[t._v("逻辑回归比高斯判别模型的泛化性能更强")]),t._v("。除此之外，计算过程需要求 “特征X” 减 “特征期望” 的协方差矩阵，所以"),_("strong",[t._v("效率会比逻辑回归低一点")]),t._v("。")])]),t._v(" "),_("p",[t._v("总的来说，就像机器学习领域中惯用的一句话，没有最好的模型，只有最合适的模型，这句话很zhengzhi正确。但我认为，就实际应用的准确率来看，"),_("strong",[t._v("深度神经网络 > 支持向量机 > 其它")]),t._v("，另外有一些像英语老师常说的 “固定搭配、死记住” 的一些适合特殊场景的算法，比如 "),_("strong",[t._v("垃圾邮件过滤器——朴素贝叶斯模型，类别性质的稀疏特征——逻辑回归模型，大数据推荐算法——XGBoost 等经验性质结论，不一定完美，但效果一定不错")]),t._v("。")]),t._v(" "),_("p",[t._v("本文是《监督学习篇》的第一篇文章，也是概括性地介绍了一下各种广泛使用的监督学习方法的特点和适用场景，在《监督学习篇》后续的文章中会详细地对每一种监督学习方法进行更深入地介绍，包括不使用机器学习相关工具包的算法代码实现示例。")]),t._v(" "),_("p",[_("strong",[t._v("参考文献")])]),t._v(" "),_("ol",[_("li",[_("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//book.douban.com/subject/10590856/",target:"_blank",rel:"noopener noreferrer"}},[t._v("《统计学习方法》 李航"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//stanford.edu/~shervine/teaching/cs-229.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Stanford CS 229 ― Machine Learning"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%25E5%2588%2586%25E7%25B1%25BB%25E5%2599%25A8",target:"_blank",rel:"noopener noreferrer"}},[t._v("wiki: 朴素贝叶斯分类器"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%2586%25B3%25E7%25AD%2596%25E6%25A0%2591",target:"_blank",rel:"noopener noreferrer"}},[t._v("wiki: 决策树"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://www.zhihu.com/question/23194489",target:"_blank",rel:"noopener noreferrer"}},[t._v("zhihu:什么是无监督学习？"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://link.zhihu.com/?target=http%3A//www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("cnblogs:支持向量机（五）SMO算法"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/ffe52db3e12b",target:"_blank",rel:"noopener noreferrer"}},[t._v("jianshu:基础-12：15分钟理解KD树"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//blog.csdn.net/linkin1005/article/details/39054023",target:"_blank",rel:"noopener noreferrer"}},[t._v("csdn: 斯坦福大学机器学习——高斯判别分析"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/56903924",target:"_blank",rel:"noopener noreferrer"}},[t._v("知乎：机器学习 · 监督学习篇 I 监督学习是什么"),_("OutboundLink")],1)])]),t._v(" "),_("p",[t._v("无监督学习（Unsupervised learning）：（待补充）")]),t._v(" "),_("p",[t._v("聚类算法（举例:谷歌新闻）:")]),t._v(" "),_("p",[t._v("（待补充）")]),t._v(" "),_("p",[t._v("鸡尾酒会算法")]),t._v(" "),_("p",[t._v("强化学习（enforment learning）：（待补充）")]),t._v(" "),_("p",[t._v("推荐系统（recommender system）：协同过滤算法，混合推荐算法（待补充）")])],1)}),[],!1,null,null,null);r.default=e.exports}}]);