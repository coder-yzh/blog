<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>PyTorch基础 | Coderyzh的博客</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/blog/logo.jpg">
    <meta name="description" content="冲鸭！">
    
    <link rel="preload" href="/blog/assets/css/0.styles.9a55a594.css" as="style"><link rel="preload" href="/blog/assets/js/app.a8766d76.js" as="script"><link rel="preload" href="/blog/assets/js/2.7533f6e6.js" as="script"><link rel="preload" href="/blog/assets/js/91.9f86ae39.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.885c6e23.js"><link rel="prefetch" href="/blog/assets/js/11.ffa3d654.js"><link rel="prefetch" href="/blog/assets/js/12.2ea34cef.js"><link rel="prefetch" href="/blog/assets/js/13.e20da210.js"><link rel="prefetch" href="/blog/assets/js/14.88d3e5c6.js"><link rel="prefetch" href="/blog/assets/js/15.fa0e7cb3.js"><link rel="prefetch" href="/blog/assets/js/16.10f56bfd.js"><link rel="prefetch" href="/blog/assets/js/17.e7f7036a.js"><link rel="prefetch" href="/blog/assets/js/18.0a46a51c.js"><link rel="prefetch" href="/blog/assets/js/19.3a71ffa9.js"><link rel="prefetch" href="/blog/assets/js/20.6dd9f744.js"><link rel="prefetch" href="/blog/assets/js/21.363db7c8.js"><link rel="prefetch" href="/blog/assets/js/22.85b912f6.js"><link rel="prefetch" href="/blog/assets/js/23.e1c78269.js"><link rel="prefetch" href="/blog/assets/js/24.87712464.js"><link rel="prefetch" href="/blog/assets/js/25.01d111c9.js"><link rel="prefetch" href="/blog/assets/js/26.5384d46a.js"><link rel="prefetch" href="/blog/assets/js/27.06a77ce7.js"><link rel="prefetch" href="/blog/assets/js/28.dee28251.js"><link rel="prefetch" href="/blog/assets/js/29.8735c1bd.js"><link rel="prefetch" href="/blog/assets/js/3.d2a5d2b1.js"><link rel="prefetch" href="/blog/assets/js/30.e01f8138.js"><link rel="prefetch" href="/blog/assets/js/31.f006e3c9.js"><link rel="prefetch" href="/blog/assets/js/32.ba3efeab.js"><link rel="prefetch" href="/blog/assets/js/33.9c85da1b.js"><link rel="prefetch" href="/blog/assets/js/34.991fc479.js"><link rel="prefetch" href="/blog/assets/js/35.77a02eab.js"><link rel="prefetch" href="/blog/assets/js/36.8c000e42.js"><link rel="prefetch" href="/blog/assets/js/37.c7e4dcad.js"><link rel="prefetch" href="/blog/assets/js/38.9c8583e2.js"><link rel="prefetch" href="/blog/assets/js/39.f78da62b.js"><link rel="prefetch" href="/blog/assets/js/4.bf5a800a.js"><link rel="prefetch" href="/blog/assets/js/40.7e03ec5e.js"><link rel="prefetch" href="/blog/assets/js/41.0e2cafc7.js"><link rel="prefetch" href="/blog/assets/js/42.c82482dd.js"><link rel="prefetch" href="/blog/assets/js/43.f1609a1d.js"><link rel="prefetch" href="/blog/assets/js/44.1e8bad32.js"><link rel="prefetch" href="/blog/assets/js/45.c3f3857d.js"><link rel="prefetch" href="/blog/assets/js/46.d18b5371.js"><link rel="prefetch" href="/blog/assets/js/47.be4f4a89.js"><link rel="prefetch" href="/blog/assets/js/48.dfcceb94.js"><link rel="prefetch" href="/blog/assets/js/49.7d93d048.js"><link rel="prefetch" href="/blog/assets/js/5.7365f518.js"><link rel="prefetch" href="/blog/assets/js/50.1df2a5f5.js"><link rel="prefetch" href="/blog/assets/js/51.adcdc2be.js"><link rel="prefetch" href="/blog/assets/js/52.f6515f82.js"><link rel="prefetch" href="/blog/assets/js/53.095ddcba.js"><link rel="prefetch" href="/blog/assets/js/54.eaa84284.js"><link rel="prefetch" href="/blog/assets/js/55.b703f464.js"><link rel="prefetch" href="/blog/assets/js/56.c92ce5f3.js"><link rel="prefetch" href="/blog/assets/js/57.fd601ef9.js"><link rel="prefetch" href="/blog/assets/js/58.82d39220.js"><link rel="prefetch" href="/blog/assets/js/59.61dd1284.js"><link rel="prefetch" href="/blog/assets/js/6.f942c28c.js"><link rel="prefetch" href="/blog/assets/js/60.4af561a9.js"><link rel="prefetch" href="/blog/assets/js/61.7e8ed391.js"><link rel="prefetch" href="/blog/assets/js/62.1b129d44.js"><link rel="prefetch" href="/blog/assets/js/63.1e8d0aea.js"><link rel="prefetch" href="/blog/assets/js/64.19d67993.js"><link rel="prefetch" href="/blog/assets/js/65.745f941d.js"><link rel="prefetch" href="/blog/assets/js/66.9cb5dd0f.js"><link rel="prefetch" href="/blog/assets/js/67.ee361403.js"><link rel="prefetch" href="/blog/assets/js/68.24bd88ba.js"><link rel="prefetch" href="/blog/assets/js/69.6fdc256e.js"><link rel="prefetch" href="/blog/assets/js/7.85e210d5.js"><link rel="prefetch" href="/blog/assets/js/70.23607091.js"><link rel="prefetch" href="/blog/assets/js/71.fdfa3eb3.js"><link rel="prefetch" href="/blog/assets/js/72.4cc9b63f.js"><link rel="prefetch" href="/blog/assets/js/73.63bde3dc.js"><link rel="prefetch" href="/blog/assets/js/74.903eb92e.js"><link rel="prefetch" href="/blog/assets/js/75.94c5054f.js"><link rel="prefetch" href="/blog/assets/js/76.e626847b.js"><link rel="prefetch" href="/blog/assets/js/77.72e060da.js"><link rel="prefetch" href="/blog/assets/js/78.0baed4f6.js"><link rel="prefetch" href="/blog/assets/js/79.5954565b.js"><link rel="prefetch" href="/blog/assets/js/8.baf7966e.js"><link rel="prefetch" href="/blog/assets/js/80.c7a4a11c.js"><link rel="prefetch" href="/blog/assets/js/81.813b9331.js"><link rel="prefetch" href="/blog/assets/js/82.eb753c9b.js"><link rel="prefetch" href="/blog/assets/js/83.14a3f24e.js"><link rel="prefetch" href="/blog/assets/js/84.cbf28e40.js"><link rel="prefetch" href="/blog/assets/js/85.5fc0e4b4.js"><link rel="prefetch" href="/blog/assets/js/86.66768a8e.js"><link rel="prefetch" href="/blog/assets/js/87.ef19bf66.js"><link rel="prefetch" href="/blog/assets/js/88.b1aac405.js"><link rel="prefetch" href="/blog/assets/js/89.4aa0624d.js"><link rel="prefetch" href="/blog/assets/js/9.b07dbdb4.js"><link rel="prefetch" href="/blog/assets/js/90.9088e008.js"><link rel="prefetch" href="/blog/assets/js/92.526f6f0a.js"><link rel="prefetch" href="/blog/assets/js/93.4a0668ae.js"><link rel="prefetch" href="/blog/assets/js/94.6d97004d.js"><link rel="prefetch" href="/blog/assets/js/95.2988fcde.js"><link rel="prefetch" href="/blog/assets/js/96.83fccfac.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.9a55a594.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><!----> <span class="site-name">Coderyzh的博客</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/blog/learn/学习汇报记录/第一周学习汇报记录2021-9-19.html" class="nav-link">
  研路之行
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="工具箱" class="dropdown-title"><span class="title">工具箱</span> <span class="arrow down"></span></button> <button type="button" aria-label="工具箱" class="mobile-dropdown-title"><span class="title">工具箱</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          在线编辑
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://tinypng.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  图片压缩
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          在线服务
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://www.aliyun.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  阿里云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://cloud.tencent.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  腾讯云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          博客指南
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://juejin.im/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  掘金
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://blog.csdn.net/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/blog/learn/学习汇报记录/第一周学习汇报记录2021-9-19.html" class="nav-link">
  研路之行
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="工具箱" class="dropdown-title"><span class="title">工具箱</span> <span class="arrow down"></span></button> <button type="button" aria-label="工具箱" class="mobile-dropdown-title"><span class="title">工具箱</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          在线编辑
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://tinypng.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  图片压缩
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          在线服务
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://www.aliyun.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  阿里云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://cloud.tencent.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  腾讯云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          博客指南
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://juejin.im/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  掘金
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://blog.csdn.net/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>学习汇报记录</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>课程学习记录</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>文献阅读笔记</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>论文学习记录</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>读书阅读记录</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-2"><p class="sidebar-heading"><span>数据挖掘概念与技术</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-2"><p class="sidebar-heading open"><span>Python深度学习基于PyTorch</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-Numpy基础.html" class="sidebar-link">NumPy基础</a></li><li><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html" class="active sidebar-link">PyTorch基础</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1numpy与tensor" class="sidebar-link">1.1Numpy与Tensor</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-1tensor概述" class="sidebar-link">1.1.1Tensor概述</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-2-创建tensor" class="sidebar-link">1.1.2 创建Tensor</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-3-修改tensor形状" class="sidebar-link">1.1.3 修改Tensor形状</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-4-索引操作" class="sidebar-link">1.1.4 索引操作</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-5利用广播机制" class="sidebar-link">1.1.5利用广播机制</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-6逐元素操作" class="sidebar-link">1.1.6逐元素操作</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-7归并操作" class="sidebar-link">1.1.7归并操作</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-8比较操作" class="sidebar-link">1.1.8比较操作</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-9矩阵操作" class="sidebar-link">1.1.9矩阵操作</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-1-10pytorch-numpy函数操作对照" class="sidebar-link">1.1.10PyTorch-Numpy函数操作对照</a></li></ul></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-2tensor与autograd" class="sidebar-link">1.2Tensor与Autograd</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-2-1标量反向传播" class="sidebar-link">1.2.1标量反向传播</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-2-2非标量反向传播" class="sidebar-link">1.2.2非标量反向传播</a></li></ul></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-3使用numpy实现机器学习" class="sidebar-link">1.3使用Numpy实现机器学习</a></li><li class="sidebar-sub-header"><a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-PyTorch基础.html#_1-4使用tensor及antograd实现机器学习" class="sidebar-link">1.4使用Tensor及Antograd实现机器学习</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-2"><p class="sidebar-heading"><span>动手学深度学习</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>名词解释</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>生活琐碎</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="pytorch基础"><a href="#pytorch基础" class="header-anchor">#</a> PyTorch基础</h1> <h2 id="_1-1numpy与tensor"><a href="#_1-1numpy与tensor" class="header-anchor">#</a> 1.1Numpy与Tensor</h2> <h3 id="_1-1-1tensor概述"><a href="#_1-1-1tensor概述" class="header-anchor">#</a> 1.1.1Tensor概述</h3> <p>如果从修改方式的角度，<code>tensor</code>的操作可以分为以下两类：</p> <ul><li>（1）不修改自身数据，如<code>x.add(y)</code>,<code>x</code>的数据不变，返回一个新的<code>tensor</code>。</li> <li>（2）修改自身数据，如<code>x.add_(y)</code>(运行符带下划线后缀)，运算结果存在<code>x</code>中，<code>x</code>被修改。</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
z <span class="token operator">=</span> x<span class="token punctuation">.</span>add<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># 不修改自身</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>  <span class="token comment"># tensor([4, 6])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># tensor([1, 2])</span>
x<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># 修改自身</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># tensor([4, 6])</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="_1-1-2-创建tensor"><a href="#_1-1-2-创建tensor" class="header-anchor">#</a> 1.1.2 创建Tensor</h3> <img src="/blog/PyTorch_Learn/2.4创建Tensor.jpg" alt="mixureSecure"> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 根据list数据生成tensor</span>
torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 根据指定形状生成tensor</span>
torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

<span class="token comment"># 根据给定的tensor的形状</span>
t <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 查看tensor的形状</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'t.size():'</span><span class="token punctuation">,</span> t<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([2, 3])</span>

<span class="token comment"># shape与size()等价方式</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'t.shape:'</span><span class="token punctuation">,</span> t<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([2, 3])</span>

<span class="token comment"># 根据已有形状创建tensor</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>t<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'根据已有形状创建tensor:\n'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0., 0., 0.],</span>
<span class="token comment">#         [0., 0., 0.]])</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><ul><li>（1）<code>torch.Tensor</code>是<code>torch.empty</code>和<code>torch.tensor</code>之间的一种混合，但是，当传入数据时，torch.Tensor使用全局默认<code>dtype（FloatTensor）</code>，<code>torch.tensor</code>从数据中推断数据类型。</li> <li>（2）<code>torch.tensor(1)</code>返回一个固定值1，而<code>torch.Tensor(1)</code>返回一个大小为1的张量，它是随机初始化的值。</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;t1的值{},t1的数据类型{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t1<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># t1的值tensor([-1.7904e+36]),t1的数据类型torch.FloatTensor</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;t2的值{},t2的数据类型{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>t2<span class="token punctuation">,</span> t2<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># t2的值1,t2的数据类型torch.LongTensor</span>

<span class="token comment"># 生成一个单位矩阵</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[1., 0.],</span>
<span class="token comment">#         [0., 1.]])</span>

<span class="token comment"># 自动生成全是0的矩阵</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0., 0., 0.],</span>
<span class="token comment">#         [0., 0., 0.]])</span>

<span class="token comment"># 根据规则生成数据</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([ 1.,  4.,  7., 10.])</span>

<span class="token comment"># 生成满足均匀分布随机数</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.6081, 0.8791, 0.1851],</span>
<span class="token comment">#         [0.6253, 0.7262, 0.4320]])</span>

<span class="token comment"># 生成满足标准分布随机数</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[ 0.1547, -1.6141,  0.7410],</span>
<span class="token comment">#         [-1.0568, -1.5053,  0.1458]])</span>

<span class="token comment"># 返回所给数据形状相同，值全为0的张量</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0., 0., 0.],</span>
<span class="token comment">#         [0., 0., 0.]])</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br></div></div><h3 id="_1-1-3-修改tensor形状"><a href="#_1-1-3-修改tensor形状" class="header-anchor">#</a> 1.1.3 修改Tensor形状</h3> <img src="/blog/PyTorch_Learn/2.4修改Tensor形状.jpg" alt="mixureSecure"> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 生成一个形状为2x3的矩阵</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

<span class="token comment"># 查看矩阵的形状</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x.size():'</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 结果为torch.Size([2, 3])</span>

<span class="token comment"># 查看x的维度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x.dim():'</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 结果为2</span>

<span class="token comment"># 把x变为3x2的矩阵</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x.view(3, 2):'</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 把x展平为1维向量</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y.shape:'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([6])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># tensor([ 0.5704, -0.5218, -0.0271, -0.4298,  0.1096, -0.1854])</span>
<span class="token comment"># 添加一个维度</span>
z <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 查看z的形状</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'z.size():'</span><span class="token punctuation">,</span> z<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 结果为torch.Size([1, 6])</span>

<span class="token comment"># 计算Z的元素个数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'z.numel():'</span><span class="token punctuation">,</span> z<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 结果为6</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><h3 id="_1-1-4-索引操作"><a href="#_1-1-4-索引操作" class="header-anchor">#</a> 1.1.4 索引操作</h3> <img src="/blog/PyTorch_Learn/2.4索引操作.jpg" alt="mixureSecure"> <ul><li><code>gather(input,dim,index)</code>:在指定维度上选择数据，输出的形状与<code>index</code>一致，其中<code>index</code>的类型必须是<code>LongTensor</code>类型的</li> <li>获取指定索引对应的值,输出根据以下规则得到：</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>out<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">[</span>index<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span>  <span class="token comment"># if dim == 0</span>
out<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token comment"># if dim == 1</span>

<span class="token comment"># 其中，i，j是index逐一遍历</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><ul><li><code>scatter_(input,dim,index,src)</code>为<code>gather</code>的反操作，根据指定索引补充数据</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 设置一个随机种子</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>

<span class="token comment"># 生成一个形状为2x3的矩阵</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[ 0.3607, -0.2859, -0.3938],</span>
<span class="token comment">#         [ 0.2429, -1.3833, -2.3134]])</span>

<span class="token comment"># 根据索引获取第1行，所有数据</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># tensor([ 0.3607, -0.2859, -0.3938])</span>

<span class="token comment"># 获取最后一列数据</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># tensor([-0.3938, -2.3134])</span>

<span class="token comment"># 生成是否大于0的Byter张量</span>
mask <span class="token operator">=</span> x <span class="token operator">&gt;</span> <span class="token number">0</span>
<span class="token comment"># 获取大于0的值</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># tensor([0.3607, 0.2429])</span>

<span class="token comment"># 获取非0下标,即行，列索引</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[0, 0],</span>
<span class="token comment">#         [1, 0]])</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x:'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[ 0.3607, -0.2859, -0.3938],</span>
<span class="token comment">#         [ 0.2429, -1.3833, -2.3134]])</span>

index <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>  <span class="token comment"># tensor([[ 0.3607, -1.3833, -2.3134]])</span>
<span class="token comment"># out[i][j],分别输出out[0][0],out[1][1],out[1][2]</span>

index <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>
<span class="token comment"># tensor([[ 0.3607, -0.2859, -0.2859],</span>
<span class="token comment">#         [-1.3833, -1.3833, -1.3833]])</span>
<span class="token comment"># 分别输出：out[0][0],out[0][1],out[0][1]</span>
<span class="token comment"># out[1][1],out[1][1],out[1][1]</span>

<span class="token triple-quoted-string string">'''
scatter_(input,dim,index,src)
为gather的反操作，根据指定索引补充数据
'''</span>

<span class="token comment"># 把b的值返回到一个2x3的0矩阵中，初始化z，化为全0矩阵</span>
z <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0., 0., 0.],</span>
<span class="token comment">#         [0., 0., 0.]])</span>

<span class="token comment"># 将b中索引的值，返回原来的位置</span>
x <span class="token operator">=</span> z<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[ 0.3607, -0.2859,  0.0000],</span>
<span class="token comment">#         [ 0.0000, -1.3833,  0.0000]])</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'4'</span> <span class="token operator">+</span> <span class="token string">'*'</span> <span class="token operator">*</span> <span class="token number">200</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br></div></div><h3 id="_1-1-5利用广播机制"><a href="#_1-1-5利用广播机制" class="header-anchor">#</a> 1.1.5利用广播机制</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>A <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># 把ndarray转换为Tensor</span>
A1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>A<span class="token punctuation">)</span>  <span class="token comment"># 形状为4x1</span>
B1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>B<span class="token punctuation">)</span>  <span class="token comment"># 形状为3</span>
<span class="token comment"># Tensor自动实现广播</span>
C <span class="token operator">=</span> A1 <span class="token operator">+</span> B1
<span class="token keyword">print</span><span class="token punctuation">(</span>C<span class="token punctuation">)</span>

<span class="token comment"># 我们可以根据广播机制，手工进行配置</span>
<span class="token comment"># 根据规则1，B1需要向A1看齐，把B变为（1,3）</span>
B2 <span class="token operator">=</span> B1<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># B2的形状为1x3</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>B2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([1, 3])</span>
<span class="token comment"># 使用expand函数重复数组，分别的4x3的矩阵</span>
A2 <span class="token operator">=</span> A1<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
B3 <span class="token operator">=</span> B2<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># 然后进行相加,C1与C结果一致</span>
C1 <span class="token operator">=</span> A2 <span class="token operator">+</span> B3
<span class="token keyword">print</span><span class="token punctuation">(</span>C1<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><h3 id="_1-1-6逐元素操作"><a href="#_1-1-6逐元素操作" class="header-anchor">#</a> 1.1.6逐元素操作</h3> <img src="/blog/PyTorch_Learn/2.4逐元素操作.jpg" alt="mixureSecure"> <div class="language-python line-numbers-mode"><pre class="language-python"><code>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

<span class="token comment"># t+(t1/t2)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>addcdiv<span class="token punctuation">(</span>t<span class="token punctuation">,</span> t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span>

<span class="token comment"># 计算sigmoid</span>
torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>t<span class="token punctuation">)</span>

<span class="token comment"># 将t限制在[0,1]之间 clamp(t,min,max)</span>
torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># t+2进行就地运算</span>
t<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h3 id="_1-1-7归并操作"><a href="#_1-1-7归并操作" class="header-anchor">#</a> 1.1.7归并操作</h3> <img src="/blog/PyTorch_Learn/2.4归并操作.jpg" alt="mixureSecure"> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 生成一个含6个数的向量</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
<span class="token comment"># 使用view方法，把a变为2x3矩阵</span>
a <span class="token operator">=</span> a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 沿y轴方向累加，即dim=0</span>
b <span class="token operator">=</span> a<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># b的形状为[3]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>  <span class="token comment"># tensor([ 6., 10., 14.])</span>
<span class="token comment"># 沿y轴方向累加，即dim=0,并保留含1的维度</span>
b <span class="token operator">=</span> a<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># b的形状为[1,3]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>  <span class="token comment"># tensor([[ 6., 10., 14.]])</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h3 id="_1-1-8比较操作"><a href="#_1-1-8比较操作" class="header-anchor">#</a> 1.1.8比较操作</h3> <img src="/blog/PyTorch_Learn/2.4比较操作.jpg" alt="mixureSecure"> <div class="language-python line-numbers-mode"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># tensor([[ 0.,  2.,  4.,  6.],</span>
<span class="token comment">#         [ 8., 10., 12., 14.],</span>
<span class="token comment">#         [16., 18., 20., 22.]])</span>

<span class="token comment"># 求所有元素的最大值</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'max:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 结果为22,max: tensor(22.)</span>

<span class="token comment"># 求y轴方向的最大值,指定了dim，额外返回下标</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y轴方向的最大值:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 结果为[16., 18., 20., 22.]</span>
<span class="token comment"># y轴方向的最大值: torch.return_types.max(</span>
<span class="token comment"># values=tensor([16., 18., 20., 22.]),</span>
<span class="token comment"># indices=tensor([2, 2, 2, 2]))</span>

<span class="token comment"># 求最大的2个元素</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最大的2个元素'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 结果为[[16., 18., 20., 22.],[ 8., 10., 12., 14.]]</span>
<span class="token comment"># 最大的2个元素 torch.return_types.topk(</span>
<span class="token comment"># values=tensor([[16., 18., 20., 22.],</span>
<span class="token comment">#         [ 8., 10., 12., 14.]]),</span>
<span class="token comment"># indices=tensor([[2, 2, 2, 2],</span>
<span class="token comment">#         [1, 1, 1, 1]]))</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><h3 id="_1-1-9矩阵操作"><a href="#_1-1-9矩阵操作" class="header-anchor">#</a> 1.1.9矩阵操作</h3> <img src="/blog/PyTorch_Learn/2.4矩阵操作.jpg" alt="mixureSecure"> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># dot对两个为1D张量进行点积运算</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'torch.dot(a, b):'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 运行结果为18,tensor(18)</span>

<span class="token comment"># mm是对2D的矩阵进行点积</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'torch.mm(x, y):'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[32, 42, 27, 32],</span>
<span class="token comment">#         [32, 50, 30, 53]])</span>

<span class="token comment"># bmm对含batch的3D进行点积运算</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'torch.bmm(x, y):'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[[28, 77, 30, 27],</span>
<span class="token comment">#          [24, 73, 25, 21]],</span>
<span class="token comment">#         [[15, 68, 57,  6],</span>
<span class="token comment">#          [25, 39, 43, 10]]])</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><h3 id="_1-1-10pytorch-numpy函数操作对照"><a href="#_1-1-10pytorch-numpy函数操作对照" class="header-anchor">#</a> 1.1.10PyTorch-Numpy函数操作对照</h3> <img src="/blog/PyTorch_Learn/2.4PyTorch-Numpy对照表.jpg" alt="mixureSecure"> <h2 id="_1-2tensor与autograd"><a href="#_1-2tensor与autograd" class="header-anchor">#</a> 1.2Tensor与Autograd</h2> <h3 id="_1-2-1标量反向传播"><a href="#_1-2-1标量反向传播" class="header-anchor">#</a> 1.2.1标量反向传播</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 1、定义叶子节点以及算子节点</span>

<span class="token comment"># 定义输入张量x</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 初始化权重参数W,偏移量b、并设置require_grad属性为True，为自动求导</span>
w <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># 实现前向传播</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>w<span class="token punctuation">,</span> x<span class="token punctuation">)</span>  <span class="token comment"># 等价于w*x</span>
z <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>y<span class="token punctuation">,</span> b<span class="token punctuation">)</span>  <span class="token comment"># 等价于y+b</span>
<span class="token comment"># 查看x,w，b页子节点的requite_grad属性</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x,w,b的require_grad属性分别为：{},{},{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>requires_grad<span class="token punctuation">,</span> w<span class="token punctuation">.</span>requires_grad<span class="token punctuation">,</span> b<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># x,w,b的require_grad属性分别为：False,True,True</span>


<span class="token comment"># 2、查看叶子节点、非叶子节点的其他属性</span>

<span class="token comment"># 查看非叶子节点的requres_grad属性,</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;y，z的requires_grad属性分别为：{},{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>requires_grad<span class="token punctuation">,</span> z<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 因与w，b有依赖关系，故y，z的requires_grad属性也是：True,True</span>

<span class="token comment"># 查看各节点是否为叶子节点</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x，w，b，y，z的是否为叶子节点：{},{},{},{},{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>is_leaf<span class="token punctuation">,</span> w<span class="token punctuation">.</span>is_leaf<span class="token punctuation">,</span> b<span class="token punctuation">.</span>is_leaf<span class="token punctuation">,</span> y<span class="token punctuation">.</span>is_leaf<span class="token punctuation">,</span> z<span class="token punctuation">.</span>is_leaf<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># x，w，b，y，z的是否为叶子节点：True,True,True,False,False</span>

<span class="token comment"># 查看叶子节点的grad_fn属性，该属性表示梯度函数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x，w，b的grad_fn属性：{},{},{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad_fn<span class="token punctuation">,</span> w<span class="token punctuation">.</span>grad_fn<span class="token punctuation">,</span> b<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 因x，w，b为用户创建的，为通过其他张量计算得到，故x，w，b的grad_fn属性：None,None,None</span>

<span class="token comment"># 查看非叶子节点的grad_fn属性，该属性表示梯度函数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;y，z的是否为叶子节点：{},{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>grad_fn<span class="token punctuation">,</span> z<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># y，z的是否为叶子节点：&lt;MulBackward0 object at 0x000001DF86F878B0&gt;,&lt;AddBackward0 object at 0x000001DF86FB7FD0&gt;</span>


<span class="token comment"># 3、自动求导，实现梯度方向传播，即梯度的反向传播。</span>
<span class="token comment"># 基于z张量进行梯度反向传播,执行backward之后计算图会自动清空，</span>
z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 如果需要多次使用backward，需要修改参数retain_graph为True，此时梯度是累加的</span>
<span class="token comment"># z.backward(retain_graph=True)</span>

<span class="token comment"># 查看叶子节点的梯度，x是叶子节点但它无需求导，故其梯度为None</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;参数w,b的梯度分别为:{},{},{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> b<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 参数w,b,x的梯度分别为:tensor([2.]),tensor([1.]),None</span>

<span class="token comment"># 非叶子节点的梯度，执行backward之后，会自动清空</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;非叶子节点y,z的梯度分别为:{},{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>retain_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> z<span class="token punctuation">.</span>retain_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 非叶子节点y,z的梯度分别为:None,None</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br></div></div><h3 id="_1-2-2非标量反向传播"><a href="#_1-2-2非标量反向传播" class="header-anchor">#</a> 1.2.2非标量反向传播</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 定义叶子节点张量x，形状为1x2</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># 初始化Jacobian矩阵</span>
J <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>J<span class="token punctuation">)</span>
<span class="token comment"># 初始化目标张量，形状为1x2</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token comment"># 定义y与x之间的映射关系：</span>
<span class="token comment"># y1=x1**2+3*x2，y2=x2**2+2*x1</span>
y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 生成y1对x的梯度</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
J<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>grad
<span class="token comment"># 梯度是累加的，故需要对x的梯度清零</span>
x<span class="token punctuation">.</span>grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>
<span class="token comment"># 生成y2对x的梯度</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
J<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>grad
<span class="token comment"># 显示jacobian矩阵的值</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>J<span class="token punctuation">)</span>
<span class="token comment"># tensor([[4., 3.],</span>
<span class="token comment">#         [2., 6.]])</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><h2 id="_1-3使用numpy实现机器学习"><a href="#_1-3使用numpy实现机器学习" class="header-anchor">#</a> 1.3使用Numpy实现机器学习</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt

np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 画图</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 随机初始化参数</span>
w1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
b1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

lr <span class="token operator">=</span> <span class="token number">0.001</span>  <span class="token comment"># 学习率</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 前向传播</span>
    y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> w1 <span class="token operator">+</span> b1
    <span class="token comment"># 定义损失函数</span>
    loss <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
    loss <span class="token operator">=</span> loss<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 计算梯度</span>
    grad_w <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    grad_b <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 使用梯度下降法，是loss最小</span>
    w1 <span class="token operator">-=</span> lr <span class="token operator">*</span> grad_w
    b1 <span class="token operator">-=</span> lr <span class="token operator">*</span> grad_b

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'predict'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span>  <span class="token comment"># true data</span>
plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>w1<span class="token punctuation">,</span> b1<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br></div></div><ul><li><p>Numpy实现的源数据：</p> <ul><li><img src="/blog/PyTorch_Learn/2.6Numpy机器学习-1.jpg" alt="mixureSecure"></li></ul></li> <li><p>可视化Numpy学习结果：</p> <ul><li><img src="/blog/PyTorch_Learn/2.6Numpy机器学习-2.jpg" alt="mixureSecure"></li></ul></li></ul> <h2 id="_1-4使用tensor及antograd实现机器学习"><a href="#_1-4使用tensor及antograd实现机器学习" class="header-anchor">#</a> 1.4使用Tensor及Antograd实现机器学习</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch <span class="token keyword">as</span> t

<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt

t<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
dtype <span class="token operator">=</span> t<span class="token punctuation">.</span><span class="token builtin">float</span>
<span class="token comment"># 生成x坐标数据，x为tenor，需要把x的形状转换为100x1</span>
x <span class="token operator">=</span> t<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># 生成y坐标数据，y为tenor，形状为100x1，另加上一些噪音</span>
y <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> x<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.2</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 画图，把tensor数据转换为numpy数据</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 随机初始化参数，参数w，b为需要学习的，故需requires_grad=True</span>
w <span class="token operator">=</span> t<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> t<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

lr <span class="token operator">=</span> <span class="token number">0.001</span>  <span class="token comment"># 学习率</span>

<span class="token keyword">for</span> ii <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 前向传播，并定义损失函数loss</span>
    y_pred <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b
    loss <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
    loss <span class="token operator">=</span> loss<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 自动计算梯度，梯度存放在grad属性中</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 手动更新参数，需要用torch.no_grad()，使上下文环境中切断自动求导的计算</span>
    <span class="token keyword">with</span> t<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        w <span class="token operator">-=</span> lr <span class="token operator">*</span> w<span class="token punctuation">.</span>grad
        b <span class="token operator">-=</span> lr <span class="token operator">*</span> b<span class="token punctuation">.</span>grad

        <span class="token comment"># 梯度清零</span>
        w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
        b<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'predict'</span><span class="token punctuation">)</span>  <span class="token comment"># predict</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span>  <span class="token comment"># true data</span>
plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br></div></div><ul><li>可视化输入数据：
<ul><li><img src="/blog/PyTorch_Learn/2.7Tensor及Antograd-1.jpg" alt="mixureSecure"></li></ul></li> <li>使用Antograd的结果：
<ul><li><img src="/blog/PyTorch_Learn/2.7Tensor及Antograd-2.jpg" alt="mixureSecure"></li></ul></li></ul></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新于:</span> <span class="time">10/4/2021, 7:17:45 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/blog/learn/文献阅读笔记/读书阅读记录/Python深度学习基于PyTorch-Numpy基础.html" class="prev">
        NumPy基础
      </a></span> <span class="next"><a href="/blog/learn/文献阅读笔记/读书阅读记录/动手学深度学习-3.html">
        3.深度学习基础
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/blog/assets/js/app.a8766d76.js" defer></script><script src="/blog/assets/js/2.7533f6e6.js" defer></script><script src="/blog/assets/js/91.9f86ae39.js" defer></script>
  </body>
</html>
